---
title: "Data"
output: html_document
---

# Data

Data should be managed and shared properly to make it useful in research, to promote transparency and facilitate reproducibility, and to ensure the credibility of research. This includes such practices as transforming data into a tidy format, storing data in open file formats, and providing data documentation.

**Recommended readings:**

Borer, Elizabeth T., Eric W. Seabloom, Matthew B. Jones, and Mark Schildhauer. 2009. “Some Simple Guidelines for Effective Data Management.” *The Bulletin of the Ecological Society of America* 90 (2): 205–14. <https://doi.org/10.1890/0012-9623-90.2.205>.

Broman, Karl W., and Kara H. Woo. 2018. “Data Organization in Spreadsheets.” *The American Statistician* 72 (1): 2–10. <https://doi.org/10.1080/00031305.2017.1375989>.

Ellis, Shannon E., and Jeffrey T. Leek. 2018. “How to Share Data for Collaboration.” *The American Statistician* 72 (1): 53–57. <https://doi.org/10.1080/00031305.2017.1375987>.

Goodman, Alyssa, Alberto Pepe, Alexander W. Blocker, Christine L. Borgman, Kyle Cranmer, Merce Crosas, Rosanne Di Stefano, et al. 2014. “Ten Simple Rules for the Care and Feeding of Scientific Data.” *PLOS Computational Biology* 10 (4): e1003542. <https://doi.org/10.1371/journal.pcbi.1003542>.

Hart, Edmund M., Pauline Barmby, David LeBauer, François Michonneau, Sarah Mount, Patrick Mulrooney, Timothée Poisot, Kara H. Woo, Naupaka B. Zimmerman, and Jeffrey W. Hollister. 2016. “Ten Simple Rules for Digital Data Storage.” *PLOS Computational Biology* 12 (10): e1005097. <https://doi.org/10.1371/journal.pcbi.1005097>.

Wilkinson, Mark D., Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al. 2016. “The FAIR Guiding Principles for Scientific Data Management and Stewardship.” *Scientific Data* 3 (March): 160018. <https://doi.org/10.1038/sdata.2016.18>.

Also see the resources available at [DataONE](https://www.dataone.org/resources).

## Tidy Data  

As researchers, we work with data from many different sources. Often these data are messy. One of the first steps of any analysis is to clean any available raw data so that you can make simple visualizations of the data, calculate simple summary statistics, look for missing or incorrect data, and eventually proceed with more involved analyses or modeling.

As part of the data cleaning process, we recommend getting all data into a "tidy" format (also known as "long" format, as opposed to "wide" format). According to the [Tidy Data Guide](https://r4ds.had.co.nz/tidy-data.html) by Garrett Grolemund and Hadley Wickham, tidy data is defined as:

<blockquote>
* Each variable must have its own column.  
* Each observation must have its own row.  
* Each value must have its own cell.  
</blockquote>

These three features of tidy data can be seen in the following figure, also from the [Tidy Data Guide](https://r4ds.had.co.nz/tidy-data.html):

<blockquote>
![](images/tidy-data.png)

</blockquote>

Once data are in this format, it makes subsequent visualization and analysis much easier. If you've ever worked with a file that has a separate column for each year (an example of "wide" format data), you know how hard that type of data format is to work with!  

As always, we recommend keeping a backup copy of the raw data you obtained from the original source, and using a reproducible script for transforming these data into a tidy data format.

### Recommended Resources  

We highly recommend the chapter on [Tidy Data](https://r4ds.had.co.nz/tidy-data.html) from the book [R for Data Science](https://r4ds.had.co.nz) by Garrett Grolemund and Hadley Wickham. This guide is geared towards R users and provides helpful tips for transforming and working with data in R, but the concepts should be broadly applicable to other languages as well. For tips specific to Python, we recommend a blogpost by Jean-Nicholas Hould titled [Tidy Data in Python](http://www.jeannicholashould.com/tidy-data-in-python.html).


## Storage

Data from all projects will be stored in the `Data` directory of our emLab shared drive. Some data will be of general interest to different projects (for example, the "Upsides database"), while some data may be relevant to just one project (*e.g.* lobster landings for November 2014 in Montserrat Island). As such, data should be stored in the appropriate folders. Data of general interest will be sotred under a `Data/shared/` folder, subsequently divided as needed. Data relevant to only a few projects will be stored under `Data/project_name`. The name of this project should match the name of the project, as defined in the [emLab Shared Drive Structure](https://docs.google.com/document/d/1a26a6N4akF2dSXWfp0fWxGegd0wvrPVUeaA09en2EPE).

### `Data/shared`

The data living under `Data/shares` will often be the product of previous projects, or clean raw data obtained from data providers. For example, the "upsides database" is the product of the [Costello *et al.* 2016 paper](https://www.pnas.org/content/113/18/5125). On the other hand, the RAM Legacy stock assessment database is often shared with us by the [RAM Legacy team](https://www.ramlegacy.org/). Therefore, when a project uses thes data as input, we make no distinction between "raw" and "processed" data, and treat all data in this folder as "raw data". This means that these data should not be modified or updated by projects. When needed, updated versions of some data may become available.

### Project-specific data

For project-specific cases, however, the teams will often receive data from partners, compile it from multiple sources, use survey responses, or extract it from a literature review. These data are termed "raw data", and should **never** be directly modified -all the errors, mistakes, and gremlins should be kept in the original versions. Instead, they should be processed / cleaned, and then exported as "clean data", that can be used in analyses.

For example, suppose that a team working in Montserrat receives a database of lobster landings by the government. These data are stored as an excel spreadsheet, and will surely contain many mistakes and errors that need to be fixed. The team will clean the data (preferabily, using a reproducible script), and then export it to a different location within the project folder. Therefore, the project-level data folders will be divided into `raw_data` and `data` folders. The first one will contain all raw data as-is. The second folder will contain clean data, whcich can then be used as input for analyses.

### General structure of the `Data` folder

```
Data
|__shared
|   |__ upsides
|   |__ RAM
|   |   |__ RAM v4.10
|   |   |__ RAM v4.15
|   |   |__ RAM v4.25
|   |   |__ RAM v4.40
|   |   |__ ...
|   |__ SST
|__ montserrat_project
    |__ raw_data
    |   |__ lobster_landings_nov_2012.xslx
    |__ data
        |__ lobster_landings_nov_2012.csv
```

## Metadata and Data Directory

Logging and storing robust metadata is important in maintaining the transparency and resuability of the data used in our analyses. Metadata records are currently listed in the [emLab Data Directory](https://docs.google.com/spreadsheets/d/1lCzpP1X0qPQrqDzVBi78XJQVUumbcQqRck60OkHtANk/edit#gid=0) located on the team's shared Google Drive. The key for the columns on the Data Directory, "the meta-metadata", can be found on the second "Metadata" tab and is also reproduced below. 

```{r render meta_metadata table, results= 'asis', echo = F, message = F, warning=F}
require(tidyverse)
require(knitr)

meta_metadatatable <- read_csv("images/meta_metadata.csv", col_names = F)
colnames(meta_metadatatable) <- c("Column","Description")
kable(meta_metadatatable)
```

