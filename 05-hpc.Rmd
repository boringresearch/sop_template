---
title: "High Performance Computing"
output: html_document
---

# High Performance Computing

Certain analysis use cases require high performance computing resources:

  * big data
  * parallel computing
  * lengthy computation times
  * restricted-use data

For analyses involving big data or models that take a long time to estimate, a single laptop or desktop computer is often not powerful enough or becomes inconvenient to use. Additionally, for analyses involving restricted-use data, such as datasets containing personally identifiable information, data use agreements typically stipulate that the data should be stored and analyzed in a secure manner.

In these cases, you should use the high performance computing resources available to emLab, including cloud computing through Google Cloud Platform and the UCSB server clusters. Cloud computing incurs costs but is flexible whereas the UCSB server clusters are free but have some limitations, such as job queues.

When to use Google Cloud Platform:

  -  need maximum computational flexibility

When to use UCSB server clusters:

  - costs are a concern
  - using Stata
  - using restricted-use data (depends on data use agreement)

## Google Cloud Platform

Google Cloud Platform (GCP) is a suite of cloud-based products that work together to provide robust and seamless solutions to high performance computing, big data storage, data analytics, machine learning and more. The platform is built on Google's internal infrastructure and it's known for it's reliability, flexibility, speed, and a relatively low cost "pay-as-you" model. At EmLab we mainly use three of GCP's products: [Cloud Storage](https://console.cloud.google.com/storage), [BigQuery](https://bigquery.cloud.google.com), and [Compute Engine](https://console.cloud.google.com/compute) and each year we have a limited amount of credits to cover the costs of using these tools for projects that require the storage and use of very large datasets, projects that require large computational power, or those that use Global Fishing Watch data. 

When it comes to high performance computing, [Compute Engine](https://console.cloud.google.com/compute) is a very useful tool. It allows us to easily create custom-made virtual machines with the storage, memory, and number of cores needed for a given task. Virtual machines can run public images of Linux, Windows Server, and can also be used to deploy Docker containers. Starting, stopping, and deleting virtual machines is easy and fast which means we have full control on the amount of resources we use and get billed for. 

To get up and running with a virtual machine, Grant McDermott (SFG alumn and fellow) wrote this really good step by step [tutorial](https://grantmcdermott.com/2017/05/30/rstudio-server-compute-engine/). Here you will learn how to create, start, connect to, and stop a virtual machine in Compute Engine and how to install Rstudio server and git. Importantly, you will also find a link that walks you through the installation of Google Cloud SDK command line utility (`gcloud`) which is a prerequisite to be able to speak to your virtual machine from your local terminal. When you install `gcloud` and autenthicate your credentials you will be able to set `ucsb-gfw` as your project which will link you to Emlab's billing account. If you have not joined `ucsb-gfw` please get in touch with and we will set you up! 

General guidelines for creating and running virtual machines:

  - Give your VM a descriptive name associated with the specific project you will be using it for. 
  - Give your VM a static IP address. That way you can add it to your bookmarks and access it easily. 
  - Always turn off your VM when not it use. Remember we get charged for every minute it is on. 
  - Delete the VM once the project is finished. That way we keep things tidy. 

## UCSB Server Clusters

The Center for Scientific Computing at UCSB provides resources and support for research involving high performance computing, including multiple server clusters for storing and analyzing data. Find out more information at <http://csc.cnsi.ucsb.edu/>.

The clusters should be used if cloud computing costs are a concern. The cluster computing resources are free to emLab researchers, but they are a shared resource among UCSB researchers and involve job queues that can potentially delay analyses. However, most of the analyses typical of emLab projects require a small amount of resources relative to other users of the clusters.

Additionally, the clusters should typically be used if using restricted-use data in research, though this depends on the terms of the data use agreement. Be sure to restrict access to any sensitive data on the clusters by changing the folder and file permissions appropriately.

Some data providers may prefer to use cloud computing services for sensitive data because it may give them greater control over the uses of their data. If needed, these issues about where data can be stored and analyzed should be negotiated and resolved in data use agreements.

A user guide for the clusters can be found at <https://emlab-ucsb.github.io/cluster-guide/>.

